### model
model_name_or_path: meta-llama/Llama-3.1-8B
trust_remote_code: true

### method
stage: sft
do_train: true
finetuning_type: full
# deepspeed: examples/deepspeed/ds_z3_config.json # GaLore is incompatible with DeepSpeed
profile_memory_from_start: true # Enable early memory profiling
profile_memory_stop_step: 4   # Dump snapshot after 8 optimizer steps and stop profiling
profile_memory_max_entries: 10000000


### GaLore configuration
use_galore: true
galore_target: all
galore_rank: 8
galore_update_interval: 150
galore_scale: 2.0
galore_proj_type: std
galore_fused: false
galore_layerwise: false
galore_lr_galore_params: 2.0e-5
galore_lr_non_galore_params: 5.0e-6

### dataset
dataset: tulu3_mixture_coding
template: tulu_v3
cutoff_len: 1024
# max_samples: 1000 # Optional: uncomment and set for quicker testing
overwrite_cache: true
preprocessing_num_workers: 16
dataloader_num_workers: 4 # Keep or adjust based on system capabilities

### output
output_dir: saves/Llama-3.1-8B/galore/sft_coding
logging_steps: 10
save_strategy: steps # Changed from save_steps to save_strategy as per llama3.1_8b_sft_coding.yaml
save_steps: 600 # Adjusted from 500 to 600 as per llama3.1_8b_sft_coding.yaml
plot_loss: true
overwrite_output_dir: true
save_only_model: false # Kept from GaLore math config
report_to: wandb

### train
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
disable_gradient_checkpointing: true
learning_rate: 1.0e-4 # Common for GaLore, higher than standard AdamW
num_train_epochs: 1.0
lr_scheduler_type: cosine
warmup_ratio: 0.03
bf16: true
pure_bf16: true
ddp_timeout: 180000000
resume_from_checkpoint: null # Keep null as default

### eval
eval_strategy: steps
val_size: 0.01
per_device_eval_batch_size: 2
eval_steps: 25 