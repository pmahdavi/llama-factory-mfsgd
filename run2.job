#!/bin/tcsh
#PBS -l ngpus=2
#PBS -l ncpus=16
#PBS -l walltime=00:30:00
#PBS -q workq@e5-cse-cbgpu02.eecscl.psu.edu
#PBS -N pt
#PBS -M pxm5426@psu.edu 
#PBS -m bea
#PBS -l mem=100g
#PBS -o pbs_results/
#PBS -e pbs_results/
cd $PBS_O_WORKDIR

###
##  You may have set your $PATH variable depending on your situation -- if your error output can't find commands, you probably need to set your $PATH
#
##  If you have your working environment/shell set up to support running your code, you can try using "qsub -V job-name" to submit your job using all of your current environmental variables.
###
source ~/.tcshrc
conda activate llama-factory-env

# Add CUDA memory configuration to help with fragmentation
setenv PYTORCH_CUDA_ALLOC_CONF "expandable_segments:True"

# Resume from checkpoint
# llamafactory-cli train /scratch/pxm5426/runs/lora-exploration/llama-factory-1/Llama-3.2-3B_opc_edu,opc_evol,opc_mceval,opc_pkg_full_ebs128_lr1e-05/training_config.yaml 
# python -m torch.distributed.run \
#   --nproc_per_node 2 scripts/dump_optim_state.py \
#   --run_dir /scratch/pxm5426/runs/lora-exploration/llama-factory-1/Llama-3.2-3B_slimorca_full_ebs128_lr1e-05 \
#   --checkpoint checkpoint-2000  


# python scripts/visualize_optim_state.py \
#   --optim_state /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_math_reasoning_full_ebs128_lr5e-06/export_full_state_checkpoint-1200/optimizer_full.pt \
#   --out_dir /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_math_reasoning_full_ebs128_lr5e-06/export_full_state_checkpoint-1200/optim_stats

# llamafactory-cli chat configs/tulu3_mix/inference-math-reasoning.yaml


# llamafactory-cli train examples/llama3.2_3b_full_sft_open_r1_math_galore.yaml
python -m torch.distributed.run --nproc_per_node 1 --master_port 29503 scripts/dump_optim_state_smaller_batch.py --run_dir /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_precise_if_full_ebs128_lr1e-05 --checkpoint checkpoint-234 --save_exp_avg_sq_only --batch_size 1 --gradient_accumulation_steps 64

# Run the second command after the first one succeeds
#python -m torch.distributed.run --nproc_per_node 1 --master_port 29504 scripts/dump_optim_state_smaller_batch.py --run_dir /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_coding_full_ebs128_lr5e-06 --checkpoint checkpoint-1111 --save_exp_avg_sq_only --batch_size 1 --gradient_accumulation_steps 64

# python -m torch.distributed.run --nproc_per_node 2 scripts/dump_optim_state.py --run_dir /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_general_full_ebs128_lr5e-06 --checkpoint checkpoint-912 --save_exp_avg_sq_only

# python -m torch.distributed.run --nproc_per_node 2 scripts/dump_optim_state.py --run_dir /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_knowledge_recall_full_ebs128_lr5e-06 --checkpoint checkpoint-820 --save_exp_avg_sq_only

# python -m torch.distributed.run --nproc_per_node 2 scripts/dump_optim_state.py --run_dir /scratch/pxm5426/runs/lora-exploration/llama-factory/Llama-3.1-8B_tulu3_mixture_math_reasoning_full_ebs128_lr5e-06 --checkpoint checkpoint-2611 --save_exp_avg_sq_only
